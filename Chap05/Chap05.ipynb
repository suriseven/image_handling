{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 수정사항\n",
        "- 이중루프에 의해 겹치는 오브젝트 제거하는 로직의 오류를 수정했습니다\n",
        "  - i, j 인덱스 비교시 i != j 가 아니라 i == j 로 비교해야 합니다\n",
        "  - 자기 자신일 경우 건너뛰는 로직이기 때문입니다\n",
        "\n",
        "- border 영역을 세그멘테이션 영역으로 처리하는 오류를 수정했습니다\n",
        "  - border 영역이 본 오브젝트 영역보다 더 크기 때문에 발생한 오류입니다\n",
        "  - border 색상 값을 확인하고 해당 색상 조건일 경우 검정색 처리하는 로직으로 수정했습니다\n",
        "\n",
        "- 이미지 1장 증강하는 스크립트의 파일명이 고유하도록 수정했습니다\n",
        "  - 오브젝트 이미지와 배경 이미지의 이름을 조합하여 고유한 이름이 되도록 했습니다\n",
        "\n",
        "- 모든 가능한 조합으로 트레이닝 데이터세트를 대량생산하는 구문을 추가했습니다\n",
        "  - 이것을 이용해서 Chap06 에서 사용합니다"
      ],
      "metadata": {
        "id": "_CdM4_OoS0sS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLj4Uvw3GCVQ"
      },
      "source": [
        "# Chap05 이미지 대량 생산\n",
        "- Chap04에서 돌리던거 마저 돌리면 대량으로 생산되기는 하겠지요\n",
        "- 그러나 여기서 말하는 대량 생산이란 이미지 생산 계획을 세우고 그에 맞게 증강을 수행하는 것을 의미합니다\n",
        "- 약간의 bash shell 커맨드를 이용하는 방법도 소개하고자 합니다\n",
        "- 여기서 소개하는 방법은 반드시 해야 하는 방법은 아니며 하나의 예시로서 제시하고자 합니다\n",
        "- 그럼 VOC2012 데이터셋부터 다시 시작해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBwm3xazGBYA"
      },
      "outputs": [],
      "source": [
        "! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "! tar xvf VOCtrainval_11-May-2012.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hQtTfHM8Efa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L6UCBf-Hzcd"
      },
      "source": [
        "# 아래 커맨드를 이용하면 python을 쓰지 않고도 오브젝트의 분포를 파악할 수 있습니다\n",
        "- 주석을 위에서부터 하나씩 풀면서 결과를 확인해봅시다\n",
        "- person 의 비율이 지나치게 높은 것을 확인할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD8t0HLUHaRu"
      },
      "outputs": [],
      "source": [
        "# ! find VOCdevkit/VOC2012/Annotations -name \"*.xml\" \n",
        "# ! find VOCdevkit/VOC2012/Annotations -name \"*.xml\" | xargs grep \"<name\" \n",
        "! find VOCdevkit/VOC2012/Annotations -name \"*.xml\" | xargs grep \"<name\" | awk '{print $2}' | sort | uniq -c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzAUkFOeWo5T"
      },
      "source": [
        "# 잠깐만요, Main task 데이터세트가 아니군요\n",
        "- Mak task 데이터세트가 있는 train.txt로 다시 해봅시다\n",
        "- 여전히 밸런스가 맞지 않습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF7vkm3iTv8J"
      },
      "outputs": [],
      "source": [
        "! cat /content/VOCdevkit/VOC2012/ImageSets/Main/train.txt | awk '{printf \"VOCdevkit/VOC2012/Annotations/%s.xml\\n\",$1}' | xargs grep \"<name\" | awk '{print $2}' | sed 's/<name>//g' | sed 's/<\\/name>//g'  | grep -v hand | grep -v head | grep -v foot |  sort | uniq -c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jn1qe00Uwqp"
      },
      "source": [
        "# 오브젝트의 크기 분포를 클래스별로 확인해봅시다\n",
        "- YOLO 모델 학습을 예시로 사용할 것이기 때문에 anchor 개념이 들어갑니다\n",
        "- 따라서 이미지 내의 오브젝트 크기가 anchor 변수에 영향을 줍니다\n",
        "- 이것도 쉘스크립트로 가능할까요?\n",
        "  - 빠른 포기하고 python 으로 넘어갑니다\n",
        "  - 어떤 방법이든 효율적으로 할 수 있는 방향으로 갑니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlfRRzNTVFfc"
      },
      "outputs": [],
      "source": [
        "! find VOCdevkit/VOC2012/Annotations -name \"*.xml\" | xargs grep \"<width\\|<height\\|<xmin\\|<ymin\\|<xmax\\|<ymax\\|<name\" | head -n 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miGmn10dXO8q"
      },
      "source": [
        "### VOC 2012 Main task 의 train 데이터세트에 대해 클래스별 오브젝트 크기 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y3q87EUVlZw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as Et\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "ANNOTATION_BASE = '/content/VOCdevkit/VOC2012/Annotations'\n",
        "ANNOTATION_SUFFIX = '.xml'\n",
        "train_txt_filename = '/content/VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
        "train_txt_file = open(train_txt_filename, 'r')\n",
        "train_files_list = train_txt_file.readlines()\n",
        "train_files = [t.strip() for t in train_files_list]\n",
        "\n",
        "object_stat = {}\n",
        "\n",
        "for train_file in train_files:\n",
        "    annotation_file = os.path.join(ANNOTATION_BASE, train_file) + ANNOTATION_SUFFIX\n",
        "\n",
        "    tree = Et.parse(annotation_file)\n",
        "    root = tree.getroot()\n",
        "    objects = root.findall(\"object\")\n",
        "    size = root.find(\"size\")\n",
        "    width = int(size.find(\"width\").text)\n",
        "    height = int(size.find(\"height\").text)\n",
        "\n",
        "    for obj in objects:\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bndbox.find(\"xmin\").text)\n",
        "        ymin = int(bndbox.find(\"ymin\").text)\n",
        "        xmax = int(bndbox.find(\"xmax\").text)\n",
        "        ymax = int(bndbox.find(\"ymax\").text)    \n",
        "        area = float((xmax - xmin) * (ymax - ymin)) / float(width * height)\n",
        "        if name not in object_stat:\n",
        "            object_stat[name] = []\n",
        "        object_stat[name].append(area)\n",
        "        # print(object_stat)\n",
        "\n",
        "\n",
        "\n",
        "for name, areas in object_stat.items():\n",
        "    # print(name, area)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.hist(areas, bins=20)\n",
        "    plt.gca().set(title='{} Histogram'.format(name), ylabel='Frequency')\n",
        "    plt.ylim(0, 1000)\n",
        "    plt.show()    \n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Xelk0JIdkN"
      },
      "source": [
        "# 아래와 같은 3단계로 진행해보고자 합니다\n",
        "\n",
        "## 1. 소스 오브젝트와 배경이미지 만들기\n",
        "- 단일 오브젝트로 구성된 이미지와, segmentation mask로 이루어지는 소스 오브젝트 구성\n",
        "- Annotation 기준으로 사물이 없는 배경으로만 이루어진 이미지\n",
        "\n",
        "## 2. 소스 오브젝트와 배경이미지를 합성하는 스크립트 만들기\n",
        "- 소스 오브젝트와 해당 오브젝트에 대한 segmentation mask를 이용하여 배경이미지에 합성합니다\n",
        "- Chap04에 했던 내용과 동일합니다\n",
        "\n",
        "## 3. python 스크립트를 호출하는 bash 스크립트 만들기\n",
        "- 파리미터를 넘기는 bash 스크립트를 만듭니다\n",
        "- 수량은 bash 스크립트로 조절합니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsZDvHLrePh"
      },
      "source": [
        "# 일단 이함수는 하나 빼놓읍시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWi5YR7rrgZY"
      },
      "outputs": [],
      "source": [
        "ANNOTATION_BASE = '/content/VOCdevkit/VOC2012/Annotations'\n",
        "JPEGIMAGE_BASE = '/content/VOCdevkit/VOC2012/JPEGImages'\n",
        "SEGMENTATION_BASE = '/content/VOCdevkit/VOC2012/SegmentationObject'\n",
        "\n",
        "JPEGIMAGE_SUFFIX = '.jpg'\n",
        "SEGMENTATION_SUFFIX = '.png'\n",
        "ANNOTATION_SUFFIX = '.xml'\n",
        "\n",
        "def display_image(image):\n",
        "    if colab_env:\n",
        "        cv2_imshow(image)\n",
        "\n",
        "    else:\n",
        "        cv2.imshow('image', image)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제가 생겨서 새로 할때 기존 출력을 지웁니다\n",
        "- -rf 옵션 사용시 삭제대상을 잘 확인하고 조심해서 사용합니다"
      ],
      "metadata": {
        "id": "UVWj6GGGTspF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3z3dCxh2-L5"
      },
      "outputs": [],
      "source": [
        "! rm -rf /content/backgrounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeQOLCJPInJ2"
      },
      "source": [
        "## 소스 배경 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYIgzSiLYj1n"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as Et\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "\n",
        "# 배경이 저장될 디렉토리 입니다(상대경로)\n",
        "save_base = '/content/backgrounds'\n",
        "os.makedirs(save_base, exist_ok=True)\n",
        "\n",
        "minimum_width = 256\n",
        "minimum_height = 256\n",
        "\n",
        "\n",
        "train_txt_filename = '/content/VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
        "train_txt_file = open(train_txt_filename, 'r')\n",
        "train_files_list = train_txt_file.readlines()\n",
        "train_files = [t.strip() for t in train_files_list]\n",
        "\n",
        "object_stat = {}\n",
        "\n",
        "for train_file in train_files:\n",
        "    org_jpg = os.path.join(JPEGIMAGE_BASE, train_file) + JPEGIMAGE_SUFFIX\n",
        "    org_xml = os.path.join(ANNOTATION_BASE, train_file) + ANNOTATION_SUFFIX\n",
        "\n",
        "    org_img = cv2.imread(org_jpg)\n",
        "    org_tree = Et.parse(org_xml)\n",
        "    org_root = org_tree.getroot()\n",
        "    org_objects = org_root.findall(\"object\")\n",
        "    org_size = org_root.find(\"size\")\n",
        "    org_width = int(org_size.find(\"width\").text)\n",
        "    org_height = int(org_size.find(\"height\").text)\n",
        "\n",
        "    # 어떤 VOC2012 이미지에서 오브젝트가 하나밖에 없는게 아니라면 무시\n",
        "    if len(org_objects) > 1:\n",
        "        continue\n",
        "\n",
        "    for obj in org_objects:\n",
        "        # Annotation 내 오브젝트 기준으로 SegmentationObject 이미지를 탐색\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bndbox.find(\"xmin\").text)\n",
        "        ymin = int(bndbox.find(\"ymin\").text)\n",
        "        xmax = int(bndbox.find(\"xmax\").text)\n",
        "        ymax = int(bndbox.find(\"ymax\").text)    \n",
        "\n",
        "        # print(org_width, org_height, xmin, ymin, xmax, ymax)\n",
        "\n",
        "        f_prefix = None\n",
        "\n",
        "        # 좌측으로 한번 자르고\n",
        "        if xmin > minimum_width and org_height > minimum_height:\n",
        "            background_img = org_img[:,:xmin]\n",
        "            f_prefix = 'left'  \n",
        "\n",
        "        # 우측으로 한번 자르고\n",
        "        elif org_width - xmax > minimum_width and org_height > minimum_height:\n",
        "            background_img = org_img[:,xmax:]    \n",
        "            f_prefix = 'right'    \n",
        "\n",
        "        # 위로 한번 자르고\n",
        "        elif ymin > minimum_height and org_width > minimum_width:\n",
        "            background_img = org_img[:ymin,:]\n",
        "            f_prefix = 'top'   \n",
        "\n",
        "        # 아래로 한번 자르고\n",
        "        elif org_height - ymax > minimum_height and org_width > minimum_width:\n",
        "            background_img = org_img[ymax:,:]\n",
        "            f_prefix = 'bottom'\n",
        "\n",
        "        if f_prefix is not None:\n",
        "            # display_image(background_img)\n",
        "\n",
        "            save_file_path = os.path.join(save_base, '{}_{}_{}.jpg'.format(f_prefix, name, train_file))\n",
        "            os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
        "            cv2.imwrite(save_file_path, background_img)\n",
        "            print(org_jpg, f_prefix, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUQalcmot9m0"
      },
      "source": [
        "## 뭔가 이상할 때에는 디버깅을 합시다\n",
        "- 꼭 디버거를 걸고 해야만 디버깅은 아닙니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKSW-bxIuSEN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import xml.etree.ElementTree as Et\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "debug_image = '/content/VOCdevkit/VOC2012/JPEGImages/2011_002851.jpg'\n",
        "debug_xml = '/content/VOCdevkit/VOC2012/Annotations/2011_002851.xml'\n",
        "img = cv2.imread(debug_image)\n",
        "\n",
        "org_xml = open(debug_xml, \"r\")\n",
        "org_tree = Et.parse(org_xml)\n",
        "org_root = org_tree.getroot()\n",
        "org_objects = org_root.findall(\"object\")\n",
        "org_size = org_root.find(\"size\")\n",
        "org_width = int(org_size.find(\"width\").text)\n",
        "org_height = int(org_size.find(\"height\").text)\n",
        "\n",
        "\n",
        "for obj in org_objects:\n",
        "    # Annotation 내 오브젝트 기준으로 SegmentationObject 이미지를 탐색\n",
        "    name = obj.find(\"name\").text\n",
        "    bndbox = obj.find(\"bndbox\")\n",
        "    xmin = int(bndbox.find(\"xmin\").text)\n",
        "    ymin = int(bndbox.find(\"ymin\").text)\n",
        "    xmax = int(bndbox.find(\"xmax\").text)\n",
        "    ymax = int(bndbox.find(\"ymax\").text)\n",
        "    img = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color=(255,0,0))\n",
        "    img = cv2.putText(img, name, org=(xmin, ymin), fontFace=cv2.FONT_HERSHEY_COMPLEX , fontScale=1.5, color=(255,0,255))\n",
        "\n",
        "if colab_env:\n",
        "    cv2_imshow(img)\n",
        "\n",
        "else:\n",
        "    cv2.imshow(img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEV50osPJTtl"
      },
      "source": [
        "## 소스 오브젝트 만들기\n",
        "- 이번에는 오브젝트 주변의 상하좌우를 배경이미지로 잘라내는 것이 아니라 그 반대입니다\n",
        "- 오브젝트 영역 내부를 잘라내겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1thcTYRKxat"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as Et\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "\n",
        "object_save_dir = '/content/objects'\n",
        "segment_save_dir = '/content/segmentations'\n",
        "\n",
        "os.makedirs(object_save_dir, exist_ok=True)\n",
        "os.makedirs(segment_save_dir, exist_ok=True)\n",
        "\n",
        "exclude_class_list = ['person']\n",
        "\n",
        "train_txt_filename = '/content/VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
        "train_txt_file = open(train_txt_filename, 'r')\n",
        "train_files_list = train_txt_file.readlines()\n",
        "train_files = [t.strip() for t in train_files_list]\n",
        "\n",
        "object_stat = {}\n",
        "\n",
        "f_index = 0\n",
        "\n",
        "for train_file in train_files:\n",
        "\n",
        "    org_jpg = os.path.join(JPEGIMAGE_BASE, train_file) + JPEGIMAGE_SUFFIX\n",
        "    org_xml = os.path.join(ANNOTATION_BASE, train_file) + ANNOTATION_SUFFIX\n",
        "    org_segmentations = os.path.join(SEGMENTATION_BASE, train_file) + SEGMENTATION_SUFFIX\n",
        "    org_img = cv2.imread(org_jpg)\n",
        "\n",
        "    if not os.path.exists(org_segmentations):\n",
        "        continue\n",
        "    org_segment = cv2.imread(org_segmentations)\n",
        "    org_tree = Et.parse(org_xml)\n",
        "    org_root = org_tree.getroot()\n",
        "    org_objects = org_root.findall(\"object\")\n",
        "    org_size = org_root.find(\"size\")\n",
        "    org_width = int(org_size.find(\"width\").text)\n",
        "    org_height = int(org_size.find(\"height\").text)\n",
        "\n",
        "    # 이번에는 이미지 내에 여러 오브젝트가 있다면 해당 오브젝트들을 모두 개별 이미지로 잘라내면 됩니다\n",
        "    \n",
        "    for obj in org_objects:\n",
        "        # Annotation 내 오브젝트 기준으로 SegmentationObject 이미지를 탐색\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bndbox.find(\"xmin\").text)\n",
        "        ymin = int(bndbox.find(\"ymin\").text)\n",
        "        xmax = int(bndbox.find(\"xmax\").text)\n",
        "        ymax = int(bndbox.find(\"ymax\").text)\n",
        "\n",
        "        # 이 구문은 일단 주석처리된 상태로 돌려봅시다\n",
        "        if (obj.find(\"occluded\") is not None and obj.find(\"occluded\").text == '1') or (obj.find(\"truncated\") is not None and obj.find(\"truncated\").text == '1'):\n",
        "            continue\n",
        "\n",
        "        cropped_image = org_img[ymin:ymax, xmin:xmax]\n",
        "        # display_image(cropped_image)\n",
        "\n",
        "        save_file_path = '{}/{}/{}_{}_{}.jpg'.format(object_save_dir, name, f_index, name, train_file) \n",
        "        os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
        "        cv2.imwrite(save_file_path, cropped_image)\n",
        "\n",
        "        cropped_segment = org_segment[ymin:ymax, xmin:xmax]\n",
        "        # display_image(cropped_segment)\n",
        "\n",
        "        save_file_path = '{}/{}/{}_{}_{}.png'.format(segment_save_dir, name, f_index, name, train_file)\n",
        "        os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
        "        cv2.imwrite(save_file_path, cropped_segment)        \n",
        "        \n",
        "        print(f_index, name, train_file)\n",
        "\n",
        "        f_index = f_index + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제가 생겨서 새로 할때 기존 출력을 지웁니다\n",
        "- -rf 옵션 사용시 삭제대상을 잘 확인하고 조심해서 사용합니다"
      ],
      "metadata": {
        "id": "L9J7sIAiT-uJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnrH3eHqH1vC"
      },
      "outputs": [],
      "source": [
        "! rm -rf /content/objects\n",
        "! rm -rf /content/segmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tm1-GBJ5GPJ"
      },
      "source": [
        "## 뭔가 또 불편합니다\n",
        "- 지정한 오브젝트 외에 함께 들어있는 오브젝트가 존재하지요\n",
        "- 오브젝트 영역 내에 다른 오브젝트가 없는 케이스로 한정해봅시다\n",
        "\n",
        "\n",
        "## 2가지 접근방법\n",
        "### 1번\n",
        "- Annotation 정보 이용하기\n",
        "  - occluded = 0 or null\n",
        "\n",
        "### 2번\n",
        "- 이중루프 돌려서 걸러내기\n",
        "  - Annotation 에서 지원하지 않아도 가능한 부분\n",
        "\n",
        "## 그 전에 IoU 라는 것을 생각합시다\n",
        "- https://en.wikipedia.org/w/index.php?title=Intersection_over_union&redirect=no\n",
        "- Intersection Over Union = 0 인 오브젝트\n",
        "- 하나의 이미지 안에서 자신을 제외한 모든 다른 오브젝트와 겹치는 영역이 없는\n",
        "  - IoU가 0인 오브젝트가 우리가 원하는 대상입니다\n",
        "- IoU 는 어떻게 계산하죠?\n",
        "  - 2개의 영역에 대한 intersection 을 구합니다\n",
        "  - 2개의 영역에 대한 union 을 구합니다\n",
        "  - intersection 나누기 union 을 리턴합니다\n",
        "- 그러면 그냥 여기서는 intersection이 0인것만 찾으면 되는거 아니에요?\n",
        "  - 네 맞아요^^;;\n",
        "  - 그러나 Object detection 에서 IoU는 항상 등장하는 개념이라 한번 짚고 넘어가 봅니다\n",
        "  - Object의 ground truth 와 predicted area가 얼마나 ground truth에 근접하는지 설명하는 수치이기 때문입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjNjZiK1IkXt"
      },
      "outputs": [],
      "source": [
        "from xml.etree.ElementTree import Element\n",
        "\n",
        "def get_iou(bndbox_i:Element, bnxbox_j:Element):  \n",
        "    xmin_i = int(bndbox_i.find(\"xmin\").text)\n",
        "    ymin_i = int(bndbox_i.find(\"ymin\").text)\n",
        "    xmax_i = int(bndbox_i.find(\"xmax\").text)\n",
        "    ymax_i = int(bndbox_i.find(\"ymax\").text)\n",
        "    box1 = [xmin_i, ymin_i, xmax_i, ymax_i]\n",
        "\n",
        "    xmin_j = int(bndbox_j.find(\"xmin\").text)\n",
        "    ymin_j = int(bndbox_j.find(\"ymin\").text)\n",
        "    xmax_j = int(bndbox_j.find(\"xmax\").text)\n",
        "    ymax_j = int(bndbox_j.find(\"ymax\").text)\n",
        "    box2 = [xmin_j, ymin_j, xmax_j, ymax_j]\n",
        "\n",
        "    intersection = get_intersection(box1, box2)\n",
        "    union = get_area(box1) + get_area(box2) - intersection\n",
        "    iou = float(intersection) / float(union)\n",
        "\n",
        "    return intersection\n",
        "\n",
        "\n",
        "def get_intersection(box1: list, box2: list):\n",
        "    box1_xmin = box1[0]\n",
        "    box1_ymin = box1[1]\n",
        "    box1_xmax = box1[2]\n",
        "    box1_ymax = box1[3]\n",
        "\n",
        "    box2_xmin = box2[0]\n",
        "    box2_ymin = box2[1]\n",
        "    box2_xmax = box2[2]\n",
        "    box2_ymax = box2[3]\n",
        "\n",
        "    xmin = box1_xmin if box1_xmin > box2_xmin else box2_xmin\n",
        "    ymin = box1_ymin if box1_ymin > box2_ymin else box2_ymin\n",
        "    xmax = box1_xmax if box1_xmax < box2_xmax else box2_xmax\n",
        "    ymax = box1_ymax if box1_ymax < box2_ymax else box2_ymax\n",
        "\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    return get_area(box)\n",
        "\n",
        "def get_area(box: list):\n",
        "    xmin = box[0]\n",
        "    ymin = box[1]\n",
        "    xmax = box[2]\n",
        "    ymax = box[3]\n",
        "\n",
        "    return (xmax - xmin) * (ymax - ymin)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8JzzDD2X2Dh"
      },
      "source": [
        "## 함수 작성을 했으니 이제 이를 이용하는 이중루프 돌려봅시다\n",
        "- 동일한 objects array를 이중루프를 돌립니다\n",
        "- 자기 자신을 제외한 나머지 모든 오브젝트와 IoU를 비교하는 것입니다\n",
        "- IoU가 0보다 크면, 즉 겹치는 영역이 조금이라도 있으면 오브젝트 추출에서 제외합니다\n",
        "- IoU가 정확히 0이면, 즉 겹치는 영역이 조금도 없으면 해당 오브젝트를 추출합니다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/objects3"
      ],
      "metadata": {
        "id": "JGKPzik4eJ1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJDlajgB5QK-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as Et\n",
        "from xml.etree.ElementTree import Element\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "# 단일 오브젝트 이미지가 저장될 디렉토리 입니다(상대경로)\n",
        "object_save_dir = '/content/objects2'\n",
        "segment_save_dir = '/content/segmentations2'\n",
        "\n",
        "exclude_class_list = ['person']\n",
        "\n",
        "\n",
        "train_txt_filename = '/content/VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
        "train_txt_file = open(train_txt_filename, 'r')\n",
        "train_files_list = train_txt_file.readlines()\n",
        "train_files = [t.strip() for t in train_files_list]\n",
        "\n",
        "object_stat = {}\n",
        "\n",
        "f_index = 0\n",
        "\n",
        "for train_file in train_files:\n",
        "\n",
        "    org_jpg = os.path.join(JPEGIMAGE_BASE, train_file) + JPEGIMAGE_SUFFIX\n",
        "    org_xml = os.path.join(ANNOTATION_BASE, train_file) + ANNOTATION_SUFFIX\n",
        "    org_segmentations = os.path.join(SEGMENTATION_BASE, train_file) + SEGMENTATION_SUFFIX\n",
        "    org_img = cv2.imread(org_jpg)\n",
        "\n",
        "    if not os.path.exists(org_segmentations):\n",
        "        continue\n",
        "    org_segment = cv2.imread(org_segmentations)\n",
        "    org_tree = Et.parse(org_xml)\n",
        "    org_root = org_tree.getroot()\n",
        "    org_objects = org_root.findall(\"object\")\n",
        "    org_size = org_root.find(\"size\")\n",
        "    org_width = int(org_size.find(\"width\").text)\n",
        "    org_height = int(org_size.find(\"height\").text)\n",
        "\n",
        "    # 이번에는 이미지 내에 여러 오브젝트가 있다면 해당 오브젝트들을 모두 개별 이미지로 잘라내면 됩니다\n",
        "    for i, obj_i in enumerate(org_objects):  \n",
        "        name = obj_i.find(\"name\").text\n",
        "\n",
        "        if name in exclude_class_list:\n",
        "            # print('excluding {}'.format(name))\n",
        "            continue\n",
        "        bndbox_i = obj_i.find(\"bndbox\")  \n",
        "        no_intersection = True\n",
        "        for j, obj_j in enumerate(org_objects):\n",
        "            bndbox_j = obj_j.find(\"bndbox\")            \n",
        "\n",
        "            # 자기 자신은 건너뜁니다 i != j가 아니라 i == j 로 비교해야 합니다\n",
        "            # 자기 자신이 아닌 오브젝트와 비교했을때 겹치는 영역이 있으면 건너뜁니다\n",
        "            if i == j or get_iou(bndbox_i, bndbox_j) > 0:\n",
        "                no_intersection = False\n",
        "                # print('intersection exists, skip')\n",
        "                break\n",
        "            \n",
        "            # 자기 자신이 아닌 오브젝트와 비교했을때 겹치는 영역이 없을 때에 한해 진행합니다\n",
        "            if no_intersection:\n",
        "                xmin = int(bndbox_i.find(\"xmin\").text)\n",
        "                ymin = int(bndbox_i.find(\"ymin\").text)\n",
        "                xmax = int(bndbox_i.find(\"xmax\").text)\n",
        "                ymax = int(bndbox_i.find(\"ymax\").text)\n",
        "\n",
        "                # 단일 오브젝트 이미지를 잘라냅니다\n",
        "                cropped_image = org_img[ymin:ymax, xmin:xmax]\n",
        "                # display_image(cropped_image)\n",
        "\n",
        "                # 단일 오브젝트 이미지에 대응되는 세그먼트를 잘라냅니다\n",
        "                cropped_segment = org_segment[ymin:ymax, xmin:xmax]\n",
        "                # display_image(cropped_segment)\n",
        "\n",
        "                # 잘라난 단일 오브젝트 이미지를 저장합니다                    \n",
        "                save_file_path = '{}/{}/{}_{}_{}.jpg'.format(object_save_dir, name, f_index, name, train_file) \n",
        "                os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
        "                cv2.imwrite(save_file_path, cropped_image)\n",
        "\n",
        "\n",
        "                # 잘라난 단일 세그먼트 이미지를 저장합니다\n",
        "                save_file_path = '{}/{}/{}_{}_{}.png'.format(segment_save_dir, name, f_index, name, train_file)\n",
        "                os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
        "                cv2.imwrite(save_file_path, cropped_segment)       \n",
        "\n",
        "                # 디버깅 용도로 print 하나 찍습니다\n",
        "                print(f_index, name, train_file)\n",
        "\n",
        "                f_index = f_index + 1\n",
        "            else:\n",
        "                print('This should not be shown')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XML Annotation 의 occluded, truncated를 이용했을 때와 비교해봅니다\n",
        "- 2011_002851 의 경우 segmentation 영역 기준으로는 겹치지 않지만 bndbox 기준으로는 겹칩니다\n",
        "- bndbox 기준으로 이중루프 돌려서 필터링한 경우에는 아래와같이 소거됨을 확인할 수 있습니다\n",
        "- 생산된 총 오브젝트 수도 더 적은 것을 확인할 수 있습니다"
      ],
      "metadata": {
        "id": "B2eab2r6Mk-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! find objects2 -name \"*2011_002851*\""
      ],
      "metadata": {
        "id": "UwomtEuGbcUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afs5PxE8IoTJ"
      },
      "source": [
        "# 몇개나 만들어졌는지 확인해볼까요?\n",
        "- 이제부터 슬슬 bash shell을 써보도록 하겠습니다\n",
        "- bash shell은 필수가 아닙니다\n",
        "  - 아래 표현은 python에서도 충분히 가능합니다\n",
        "  - 다만, python 에서 import os , os.walk 쓰는 시간에 bash 한줄로 가능하기 때문에 일단 이렇게 사용하겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttetSyc4Inm1"
      },
      "outputs": [],
      "source": [
        "! find /content/backgrounds -name \"*.jpg\" | wc -l | awk  '{printf \"Total background images: %s\\n\", $1}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3PeZ4fWJGH0"
      },
      "outputs": [],
      "source": [
        "! find /content/objects -name \"*.jpg\" | awk -F\"/\" '{print $4}' | sort | uniq -c | awk '{print $2, $1}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5yAocAYJIl4"
      },
      "outputs": [],
      "source": [
        "! find /content/segmentations -name \"*.png\" | awk -F\"/\" '{print $4}' | sort | uniq -c | awk '{print $2, $1}'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 원래 목적대로 이미지 한장 만드는 함수를 만들어봅시다\n",
        "- 필요한것\n",
        "  - 원본 오브젝트 이미지\n",
        "  - 배경\n",
        "  - 세그멘테이션 마스크\n",
        "\n",
        "- 반환하는 값\n",
        "  - 합성된 이미지\n",
        "  - 합성된 이미지 내의 오브젝트 좌표"
      ],
      "metadata": {
        "id": "H7BzisbJXwLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO annotation 생성을 위해 classes.txt 를 먼저 만듭니다\n",
        "! cat /content/VOCdevkit/VOC2012/ImageSets/Main/train.txt | awk '{printf \"VOCdevkit/VOC2012/Annotations/%s.xml\\n\",$1}' | xargs grep \"<name\" | awk '{print $2}' | sed 's/<name>//g' | sed 's/<\\/name>//g'  | grep -v hand | grep -v head | grep -v foot |  sort | uniq > classes.txt"
      ],
      "metadata": {
        "id": "cfWGkQYp44M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import traceback\n",
        "import random\n",
        "import xml.etree.ElementTree as Et\n",
        "\n",
        "colab_env = True\n",
        "\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "except:\n",
        "    colab_env = False\n",
        "\n",
        "\n",
        "def read_classes():\n",
        "    with open('classes.txt', 'r') as f:\n",
        "        return [t.strip() for t in f.readlines()]\n",
        "\n",
        "\n",
        "def build_yolo_label(filename, class_index, augmented_image, augmented_coordinate):\n",
        "    with open(filename, 'w') as f:\n",
        "        bg_height, bg_width, bg_channel = augmented_image.shape\n",
        "\n",
        "        # [[50,50],[100,100]]\n",
        "        object_xmin = augmented_coordinate[0][0]\n",
        "        object_ymin = augmented_coordinate[0][1]\n",
        "        object_width = augmented_coordinate[1][0] - augmented_coordinate[0][0]\n",
        "        object_height = augmented_coordinate[1][1] - augmented_coordinate[0][1]\n",
        "\n",
        "        x_center = (object_xmin + object_width/2)/bg_width\n",
        "        y_center = (object_ymin + object_height/2)/bg_height\n",
        "        width = object_width / bg_width\n",
        "        height = object_height / bg_height\n",
        "\n",
        "        annotation = '{} {} {} {} {}'.format(class_index, x_center, y_center, width, height)\n",
        "        f.write(annotation)\n",
        "\n",
        "\n",
        "# 이 함수의 오류를 수정합니다\n",
        "# border의 영역이 본체(?) 의 영역보다 더 클수 있습니다 /content/segmentations/bird/284_bird_2009_000454.png 의 경우가 그러합니다\n",
        "# 따라서 그냥 border 영역의 색깔 [192 224 224] 을 잡아서 해당 영역을 제거하는 방식을 사용합니다\n",
        "def remove_border(jpeg_image_path, segmented_image_path):    \n",
        "\n",
        "    original_image = cv2.imread(jpeg_image_path)\n",
        "    segmented_image = cv2.imread(segmented_image_path)\n",
        "    segmented_image[(segmented_image == [192, 224, 224]).all(axis=2)] = [0,0,0]\n",
        "\n",
        "    return segmented_image\n",
        "\n",
        "    # 아래 내용은 히스토리로 남겨두고 사용하지 않습니다\n",
        "    segmented_image_arr = (np.array(segmented_image)).reshape(-1,3)\n",
        "\n",
        "    colors, counts = np.unique(segmented_image_arr, axis=0, return_counts=1)\n",
        "\n",
        "    counts = counts.tolist()\n",
        "    colors = colors.tolist()    \n",
        "    black_index = colors.index([0,0,0])    \n",
        "\n",
        "    del colors[black_index]\n",
        "    del counts[black_index] \n",
        "    max_color = colors[counts.index(max(counts))]\n",
        "\n",
        "    original_image_arr = (np.array(original_image.copy())).reshape(-1,3)\n",
        "\n",
        "    for s, pixel in enumerate(segmented_image_arr):\n",
        "        if not (pixel == max_color).all():\n",
        "            segmented_image_arr[s] = [0,0,0]\n",
        "\n",
        "    segmented_image_arr = segmented_image_arr.reshape(segmented_image.shape)\n",
        "\n",
        "    return segmented_image_arr\n",
        "\n",
        "# 사이즈와 위치를 랜덤하게 변화시키는 로직을 추가했습니다\n",
        "def create_augmented_image(original_image_path, background_image_path, segmented_image_path):\n",
        "    \n",
        "    minimum_size = 0.1\n",
        "\n",
        "    original_image = cv2.imread(original_image_path)\n",
        "\n",
        "    segmented_image = remove_border(jpeg_image_path=original_image_path, segmented_image_path=segmented_image_path)\n",
        "\n",
        "    background_jpg = background_image_path\n",
        "    background_img = cv2.imread(background_jpg)\n",
        "    \n",
        "    org_height, org_width, org_channel = original_image.shape\n",
        "    bg_height, bg_width, bg_channel = background_img.shape\n",
        "    \n",
        "    width_ratio = float(org_width) / float(bg_width)\n",
        "    height_ratio = float(org_height) / float(bg_height)\n",
        "    \n",
        "    if height_ratio > width_ratio:\n",
        "        maximum_size = height_ratio\n",
        "    else:\n",
        "        maximum_size = width_ratio\n",
        "    \n",
        "    if maximum_size > 1:\n",
        "        maximum_size = 0.8\n",
        "        \n",
        "    size = random.uniform(minimum_size, maximum_size)    \n",
        "    \n",
        "    if org_height > org_width:\n",
        "        new_size = ( int((float(bg_height * size) / float(org_height)) * org_width), int(bg_height * size))\n",
        "    else:\n",
        "        new_size = (int(bg_width * size),  int((float(bg_width * size) / float(org_width)) * org_height))\n",
        "    \n",
        "    original_image = cv2.resize(original_image, dsize=new_size)\n",
        "    segmented_image = cv2.resize(segmented_image, dsize=new_size)                                \n",
        "\n",
        "    background_height, background_width, background_channel = background_img.shape\n",
        "\n",
        "    object_height, object_width, object_channel = original_image.shape\n",
        "\n",
        "#     x_start = int((background_width - object_width)/2)\n",
        "#     y_start = int((background_height - object_height)/2)\n",
        "    x_start = int(random.uniform(0, float(bg_width - new_size[0]) / float(bg_width)) * bg_width)\n",
        "    y_start = int(random.uniform(0, float(bg_height - new_size[1]) / float(bg_height)) * bg_height)\n",
        "\n",
        "    new_original_image = np.zeros(background_img.shape, dtype=np.uint8)\n",
        "    new_segmented_image = np.zeros(background_img.shape, dtype=np.uint8)                        \n",
        "    new_original_image[y_start:y_start+object_height,x_start:x_start+object_width] = original_image        \n",
        "    new_segmented_image[y_start:y_start+object_height,x_start:x_start+object_width] = segmented_image\n",
        "    \n",
        "#     print('size', x_start, y_start)\n",
        "\n",
        "    new_segmented_image = cv2.cvtColor(new_segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    final_image = cv2.copyTo(new_original_image, new_segmented_image, background_img)\n",
        "\n",
        "    new_xmin = x_start\n",
        "    new_ymin = y_start\n",
        "    new_xmax = x_start + object_width\n",
        "    new_ymax = y_start + object_height\n",
        "\n",
        "    return final_image, [[new_xmin, new_ymin], [new_xmax, new_ymax]]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if len(sys.argv) < 4:\n",
        "        print('not enough arguments')\n",
        "    else:\n",
        "        classes = read_classes()\n",
        "\n",
        "        original_image_path = sys.argv[1]\n",
        "        background_image_path = sys.argv[2]\n",
        "        segmented_image_path = sys.argv[3]\n",
        "\n",
        "        # 오브젝트와 배경의 조합이므로 오브젝트 파일 이름과 배경 파일 이름의 조합으로 생성하면 고유값을 유지할 수 있습니다. split으로 확장자를 제거합니다\n",
        "        original_image_filename = os.path.basename(original_image_path).split('.')[0]\n",
        "        background_image_filename = os.path.basename(background_image_path).split('.')[0]\n",
        "\n",
        "        # 지정된 클래스파일 기준으로 했을 때, 증강되는 오브젝트의 클래스 인덱스가 몇번인지 확인합니다\n",
        "        classname = original_image_path.split('/')[3]\n",
        "        class_index = classes.index(classname)\n",
        "\n",
        "        # 증강 이미지와 annotation을 1장 생성합니다\n",
        "        augmented_image, augmented_coordinate = create_augmented_image(original_image_path, background_image_path, segmented_image_path)\n",
        "        \n",
        "        if augmented_image is None:\n",
        "            sys.exit(0)              \n",
        "\n",
        "        augmented_image_filename = '{}/{}/{}/{}-{}.jpg'.format(save_dir, classname, bg_classname, original_image_filename, background_image_filename)\n",
        "        os.makedirs(os.path.dirname(augmented_image_filename), exist_ok=True)\n",
        "        cv2.imwrite(augmented_image_filename, augmented_image)      \n",
        "        augmented_label_filename = '{}/{}/{}/{}-{}.txt'.format(save_dir, classname, bg_classname, original_image_filename, background_image_filename)\n",
        "        \n",
        "        build_yolo_label(augmented_label_filename, class_index, augmented_image, augmented_coordinate)\n",
        "        \n",
        "        print(augmented_image_filename)"
      ],
      "metadata": {
        "id": "H5Z9sFtLYB31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = read_classes()\n",
        "\n",
        "def call_create_augmented_image(original_image_path, background_image_path, segmented_image_path, save_dir='augmented_images', size = 0.5):\n",
        "\n",
        "        # 오브젝트와 배경의 조합이므로 오브젝트 파일 이름과 배경 파일 이름의 조합으로 생성하면 고유값을 유지할 수 있습니다. split으로 확장자를 제거합니다\n",
        "        original_image_filename = os.path.basename(original_image_path).split('.')[0]\n",
        "        background_image_filename = os.path.basename(background_image_path).split('.')[0]\n",
        "\n",
        "        # 지정된 클래스파일 기준으로 했을 때, 증강되는 오브젝트의 클래스 인덱스가 몇번인지 확인합니다\n",
        "        classname = original_image_path.split('/')[1]\n",
        "        bg_classname = background_image_path.split('/')[1].split('_')[1]\n",
        "        class_index = classes.index(classname)\n",
        "\n",
        "        # 증강 이미지와 annotation을 1장 생성합니다\n",
        "        augmented_image, augmented_coordinate = create_augmented_image(original_image_path, background_image_path, segmented_image_path)\n",
        "        \n",
        "        if augmented_image is None:\n",
        "            return              \n",
        "\n",
        "        augmented_image_filename = '{}/{}/{}/{}-{}.jpg'.format(save_dir, classname, bg_classname, original_image_filename, background_image_filename)\n",
        "        os.makedirs(os.path.dirname(augmented_image_filename), exist_ok=True)\n",
        "        cv2.imwrite(augmented_image_filename, augmented_image)      \n",
        "        augmented_label_filename = '{}/{}/{}/{}-{}.txt'.format(save_dir, classname, bg_classname, original_image_filename, background_image_filename)\n",
        "        \n",
        "        build_yolo_label(augmented_label_filename, class_index, augmented_image, augmented_coordinate)\n",
        "        \n",
        "        print(augmented_image_filename)"
      ],
      "metadata": {
        "id": "wRiZNEvR3FUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 함수 동작을 검증해봅시다"
      ],
      "metadata": {
        "id": "GiVtG4skeub_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_image, augmented_coordinate = create_augmented_image( original_image_path = '/content/objects/bird/337_bird_2009_001385.jpg', \\\n",
        "    background_image_path = '/content/backgrounds/bottom_aeroplane_2009_002314.jpg', \\\n",
        "    segmented_image_path = '/content/segmentations/bird/337_bird_2009_001385.png')\n",
        "\n",
        "display_image(augmented_image)\n",
        "augmented_image_image_with_label = cv2.rectangle(augmented_image, augmented_coordinate[0], augmented_coordinate[1], (0,0,255), 2)\n",
        "\n",
        "display_image(augmented_image_image_with_label)"
      ],
      "metadata": {
        "id": "mbUwr7Bjd_qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모든 가능한 조합으로 대량 생산하기"
      ],
      "metadata": {
        "id": "6b8hoMCV3aK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "\n",
        "\n",
        "original_image_dir = 'objects'\n",
        "background_image_dir = 'backgrounds'\n",
        "segmented_image_dir = 'segmentations'\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(original_image_dir):\n",
        "    for f in files:\n",
        "        for root2, dirs2, files2 in os.walk(background_image_dir):\n",
        "            for f2 in files2:\n",
        "                try:\n",
        "                    original_image_path = os.path.join(root, f)\n",
        "                    background_image_path = os.path.join(root2, f2)\n",
        "                    segmented_image_path = original_image_path.replace('objects', 'segmentations').replace('.jpg', '.png')\n",
        "                    call_create_augmented_image(original_image_path, background_image_path, segmented_image_path)\n",
        "                except:\n",
        "                    # 디버깅이 완료되고 나면 이곳을 주석처리 합시다\n",
        "                    # traceback.print_exc()\n",
        "                    print('error', original_image_path, background_image_path, segmented_image_path)\n"
      ],
      "metadata": {
        "id": "_algD8Mj3ZpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일로 따로 빼서 검증해봅시다\n",
        "- 위에 만든 함수를 py 파일로 저장하고 아래와 같이 실행해봅니다\n",
        "- 그러면 이 파일만 대량으로 호출하면 대량 생산이 되겠네요"
      ],
      "metadata": {
        "id": "d8VdfuOUoekX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! find /content/objects/bird | awk '{printf \"python create_images.py %s %s %s\\n\", $1,$2,$3}' | bash"
      ],
      "metadata": {
        "id": "-6G7O5-JlIZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat /content/VOCdevkit/VOC2012/ImageSets/Main/train.txt | awk '{printf \"VOCdevkit/VOC2012/Annotations/%s.xml\\n\",$1}' | xargs grep \"<name\" | awk '{print $2}' | sed 's/<name>//g' | sed 's/<\\/name>//g'  | grep -v hand | grep -v head | grep -v foot |  sort | uniq > classes.txt\n",
        "! python create_image.py /content/objects/bird/284_bird_2009_000454.jpg /content/backgrounds/bottom_aeroplane_2009_002314.jpg /content/segmentations/bird/284_bird_2009_000454.png "
      ],
      "metadata": {
        "id": "-AzDypf5oR3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD7zUvx9bOfd"
      },
      "source": [
        "# 이렇게 해서 좋은 점이 무엇인가요?\n",
        "- 증강 계획에 따라 조합을 만들기 좋습니다\n",
        "  - 증강이 필요한 클래스 위주로 증강\n",
        "  - 이미 실존 이미지가 많은 클래스까지 증강을 하면 클래스 분포 불균형이 해결되지 않겠지요\n",
        "\n",
        "- 실행중 메모리 관리에 자신이 없을때 좋습니다\n",
        "  - 증강 하다가 메모리 부족으로 죽는 경우를 줄일 수 있습니다\n",
        "  - 프로세스의 시작과 종료가 클래스 단위로 발생하기 때문이지요\n",
        "  - 메모리가 정말 부족하면 1장 단위로 증강하는 스크립트를 만들면 좀더 메모리 관리가 쉽습니다\n",
        "\n",
        "- 이미지 증강 데이터세트의 관리가 쉬워집니다\n",
        "  - 증강 이미지 데이터세트를 일일이 저장하기 어려워지고 데이터세트 관리가 깨지는 순간이 분명히 올겁니다 \n",
        "  - 이 때 필요한게 무엇? DevOps? MLOps? \n",
        "  - 우리는 AugOps를 합시다 -> 이런 용어가 있는지는 모르겠지만 우리 과정에 맞게 이렇게 불러봅니다\n",
        "  - 이미지 데이터세트를 관리하는것이 아니라 증강 파라미터와 호출 명령세트를 관리합니다\n",
        "\n",
        "- 멀티 프로세싱을 하기 쉽습니다\n",
        "  - 별도로 python 코드 내에서 멀티 프로세싱/멀티 스레딩을 구현하지 않으면 아무리 좋은 장비를 가지고 있어도 단일코어만 사용하게 됩니다\n",
        "  - bash 스크립트를 이용하면 python 코드 내에서 멀티 프로세싱/멀티 스레딩을 구현하지 않아도 멀티코어를 쉽게 활용할 수 있습니다\n",
        "  - AugOps를 하려고 해도 그 재현에 시간이 오래 걸리면 의미가 없겠지요, 이 때 필요한게 멀티 프로세싱"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-trained 모델을 이용한 이미지 소스 생산\n",
        "- 대량생산을 위한 준비가 다 되었습니다, 이제 원하는대로 호출만 하면 됩니다\n",
        "- 그런데 혹시 원하는 이미지 소스가 부족한가요?\n",
        "\n",
        "## COCO Unlabeled 데이터셋을 사용해봅시다\n",
        "- http://images.cocodataset.org/zips/unlabeled2017.zip\n",
        "\n",
        "\n",
        "## 여기에 Pre-grained 모델로 세그멘테이션 마스크를 생성해봅시다\n",
        "- https://github.com/divamgupta/image-segmentation-keras\n"
      ],
      "metadata": {
        "id": "Mft2Jikjg575"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! wget http://images.cocodataset.org/zips/unlabeled2017.zip\n",
        "! wget http://images.cocodataset.org/zips/val2017.zip\n",
        "! unzip val2017.zip"
      ],
      "metadata": {
        "id": "rtjALl_uixxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade git+https://github.com/divamgupta/image-segmentation-keras"
      ],
      "metadata": {
        "id": "eTYaI9uphauj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow==2.4.1\n",
        "! pip install keras==2.4.3\n",
        "# ! pip install tensorflow-gpu==2.4.1"
      ],
      "metadata": {
        "id": "hjblQt3GkjZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(cv2.imread('/content/val2017/000000005477.jpg'))"
      ],
      "metadata": {
        "id": "BlfZ7xD1ly9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_segmentation.pretrained import pspnet_50_ADE_20K , pspnet_101_cityscapes, pspnet_101_voc12\n",
        "\n",
        "model = pspnet_101_voc12() # load the pretrained model trained on Pascal VOC 2012 dataset\n",
        "\n",
        "# load any of the 3 pretrained models\n",
        "\n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/val2017/000000005477.jpg\",\n",
        "    out_fname=\"/content/000000005477.png\")"
      ],
      "metadata": {
        "id": "b5sfCLpdiUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(cv2.imread('/content/000000005477.png'))"
      ],
      "metadata": {
        "id": "Zqgt1rGAcpb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 세그멘테이션 마스크 색상\n",
        "- 세그멘테이션 마스크상의 배경색이 검정색이 아니므로 약간 변경이 필요합니다\n",
        "- 배경색의 BGR 코드는 [197, 215, 20] 입니다"
      ],
      "metadata": {
        "id": "ow-NEs8mbi1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/000000005477.png')\n",
        "image[(image == [197, 215, 20]).all(axis=2)] = [0,0,0]"
      ],
      "metadata": {
        "id": "tO_riSbFlmtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imwrite('000000005477.png', image)\n",
        "display_image(image)"
      ],
      "metadata": {
        "id": "gBbnAgdFlxxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 완성되었으니 테스트 해볼까요?"
      ],
      "metadata": {
        "id": "347JkkPmnsM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width, channel = cv2.imread('/content/backgrounds/bottom_aeroplane_2009_002314.jpg').shape\n",
        "\n",
        "cv2.imwrite('/content/000000005477.png',  cv2.resize(cv2.imread('/content/000000005477.png'), (width, height)))\n",
        "cv2.imwrite('/content/000000005477.jpg',  cv2.resize(cv2.imread('/content/val2017/000000005477.jpg'), (width, height)))"
      ],
      "metadata": {
        "id": "pN4jD0ypod8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imread('/content/backgrounds/bottom_aeroplane_2010_003259.jpg').shape\n",
        "cv2.imread('/content/000000005477.png').shape"
      ],
      "metadata": {
        "id": "DJ5ESsMwoz-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_image, augmented_coordinate = create_augmented_image( original_image_path = '/content/000000005477.jpg', \\\n",
        "    background_image_path = '/content/backgrounds/bottom_aeroplane_2009_002314.jpg', \\\n",
        "    segmented_image_path = '/content/000000005477.png')\n",
        "\n",
        "display_image(augmented_image)\n",
        "augmented_image_image_with_label = cv2.rectangle(augmented_image, augmented_coordinate[0], augmented_coordinate[1], (0,0,255), 2)\n",
        "\n",
        "display_image(augmented_image_image_with_label)"
      ],
      "metadata": {
        "id": "Z3HImUFon7Jw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y4Xelk0JIdkN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}